# å®ä½“å…³ç³»æŠ½å–å·¥å…· (Entity Relation Extractor)

æœ¬å·¥å…·é›†æä¾›äº†ä»å¯¹è¯æ–‡æœ¬ä¸­æŠ½å–å®ä½“å’Œå…³ç³»çš„å®Œæ•´è§£å†³æ–¹æ¡ˆï¼Œç‰¹åˆ«é’ˆå¯¹LoCoMoæ•°æ®é›†è¿›è¡Œäº†ä¼˜åŒ–ã€‚æ”¯æŒå•ä¸ªæ ·æœ¬å¤„ç†ã€æ‰¹é‡å¤„ç†ã€çŸ¥è¯†å›¾è°±æ„å»ºå’Œæ•°æ®é›†åˆ¶ä½œã€‚

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

- ğŸ¤– **LLMé©±åŠ¨çš„å®ä½“å…³ç³»æŠ½å–**ï¼šä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œæ™ºèƒ½æŠ½å–
- ğŸ“Š **ç»“æ„åŒ–è¾“å‡º**ï¼šæ”¯æŒJSONæ ¼å¼çš„ç»“æ„åŒ–å“åº”è§£æ
- ğŸ¯ **å•æ ·æœ¬å¤„ç†**ï¼šé’ˆå¯¹LoCoMoæ•°æ®é›†ä¸­çš„å•ä¸ªsample_idè¿›è¡Œå¤„ç†
- ğŸ”„ **æ‰¹é‡å¤„ç†**ï¼šæ”¯æŒå¤šä¸ªæ ·æœ¬çš„æ‰¹é‡å¤„ç†
- ğŸ•¸ï¸ **çŸ¥è¯†å›¾è°±æ„å»º**ï¼šæ„å»ºå®Œæ•´çš„NetworkXçŸ¥è¯†å›¾è°±
- ğŸ’¾ **å¤šç§å­˜å‚¨æ ¼å¼**ï¼šæ”¯æŒSemanticMapå’ŒNetworkXå›¾ç»“æ„ä¿å­˜
- ğŸ“ˆ **è¯¦ç»†ç»Ÿè®¡**ï¼šæä¾›å®Œæ•´çš„å¤„ç†å’ŒæŠ½å–ç»Ÿè®¡ä¿¡æ¯
- ğŸ—‚ï¸ **æ•°æ®é›†åˆ¶ä½œ**ï¼šå°†æŠ½å–ç»“æœæ•´åˆæˆç»Ÿä¸€çš„æ•°æ®é›†æ–‡ä»¶
- ğŸ” **æ™ºèƒ½åˆ†å—**ï¼šæ”¯æŒé•¿æ–‡æœ¬çš„æ™ºèƒ½åˆ†å—å¤„ç†
- ğŸ“‹ **ä½ç½®è¿½è¸ª**ï¼šè¿½è¸ªæŠ½å–å†…å®¹åœ¨åŸæ–‡ä¸­çš„å…·ä½“ä½ç½®

## ğŸ“ ç›®å½•ç»“æ„

```
benchmark/extractor/
â”œâ”€â”€ entity_relation_extractor.py      # æ ¸å¿ƒå®ä½“å…³ç³»æŠ½å–å™¨
â”œâ”€â”€ semantic_graph_integrator.py      # è¯­ä¹‰å›¾é›†æˆå™¨
â”œâ”€â”€ locomo_entity_extractor.py        # LoCoMoä¸“ç”¨å®ä½“æŠ½å–å™¨
â”œâ”€â”€ dataset_inserter.py              # å¯¹è¯è¯­ä¹‰å­˜å‚¨å™¨
â”œâ”€â”€ dataset_maker.py                 # æ•°æ®é›†åˆ¶ä½œå™¨
â”œâ”€â”€ extract_entities_cli.py          # å‘½ä»¤è¡Œå·¥å…·
â”œâ”€â”€ example.py                       # ä½¿ç”¨ç¤ºä¾‹
â”œâ”€â”€ quick_sample_test.py             # å¿«é€Ÿæµ‹è¯•è„šæœ¬
â””â”€â”€ readme.md                        # æœ¬æ–‡æ¡£
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

ç¡®ä¿å·²å®‰è£…æ‰€éœ€ä¾èµ–ï¼š

```bash
pip install sentence-transformers
pip install networkx
pip install faiss-cpu  # æˆ– faiss-gpu
pip install numpy pandas
pip install tiktoken
```

### 2. è®¾ç½®ç¯å¢ƒå˜é‡

```bash
# è®¾ç½®APIå¯†é’¥
export DEEPSEEK_API_KEY="your-deepseek-api-key"
export OPENAI_API_KEY="your-openai-api-key"

# æˆ–è€…åœ¨æ ¹ç›®å½•åˆ›å»º .env æ–‡ä»¶
DEEPSEEK_API_KEY=your-deepseek-api-key
OPENAI_API_KEY=your-openai-api-key
```

### 3. åŸºæœ¬ä½¿ç”¨

#### æŸ¥çœ‹å¯ç”¨æ ·æœ¬
```bash
cd /home/zyh/code/AgentMemorySystem
python benchmark/extractor/locomo_entity_extractor.py \
    --dataset benchmark/dataset/locomo/locomo10.json \
    --list-samples
```

#### å¤„ç†å•ä¸ªæ ·æœ¬
```bash
python benchmark/extractor/locomo_entity_extractor.py \
    --dataset benchmark/dataset/locomo/locomo10.json \
    --sample-id conv-26 \
    --use-chunking \
    --save-intermediate \
    --output benchmark/results/conv26_extraction
```

#### å¿«é€Ÿæµ‹è¯•
```bash
python benchmark/extractor/example.py
```

## ğŸ“š è¯¦ç»†ä½¿ç”¨æŒ‡å—

### LoCoMoå®ä½“æŠ½å–å™¨ (locomo_entity_extractor.py)

ä¸“é—¨ç”¨äºå¤„ç†LoCoMoæ•°æ®é›†çš„å®ä½“å…³ç³»æŠ½å–ï¼Œæ”¯æŒä½ç½®è¿½è¸ªå’Œæ™ºèƒ½åˆ†å—ã€‚

#### åŸºæœ¬å‘½ä»¤

```bash
python benchmark/extractor/locomo_entity_extractor.py [OPTIONS]
```

#### å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | å¿…éœ€ | è¯´æ˜ |
|------|------|------|------|
| `--dataset` | str | âœ… | LoCoMoæ•°æ®é›†è·¯å¾„ |
| `--sample-id` | str | âŒ | è¦å¤„ç†çš„æ ·æœ¬ID |
| `--list-samples` | flag | âŒ | åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ ·æœ¬ID |
| `--batch` | list | âŒ | æ‰¹é‡å¤„ç†æŒ‡å®šçš„æ ·æœ¬ID |
| `--batch-all` | flag | âŒ | æ‰¹é‡å¤„ç†æ‰€æœ‰æ ·æœ¬ |
| `--use-chunking` | flag | âŒ | ä½¿ç”¨æ™ºèƒ½åˆ†å—å¤„ç†é•¿æ–‡æœ¬ |
| `--no-chunking` | flag | âŒ | ç¦ç”¨åˆ†å—å¤„ç† |
| `--save-intermediate` | flag | âŒ | ä¿å­˜ä¸­é—´ç»“æœ |
| `--output` | str | âŒ | è¾“å‡ºç›®å½• |

#### ä½¿ç”¨ç¤ºä¾‹

**1. åˆ—å‡ºæ‰€æœ‰æ ·æœ¬**
```bash
python benchmark/extractor/locomo_entity_extractor.py \
    --dataset benchmark/dataset/locomo/locomo10.json \
    --list-samples
```

**2. å¤„ç†å•ä¸ªæ ·æœ¬ï¼ˆæ¨èï¼‰**
```bash
python benchmark/extractor/locomo_entity_extractor.py \
    --dataset benchmark/dataset/locomo/locomo10.json \
    --sample-id conv-26 \
    --use-chunking \
    --save-intermediate \
    --output benchmark/results/conv26_full_extraction
```

**3. æ‰¹é‡å¤„ç†æŒ‡å®šæ ·æœ¬**
```bash
python benchmark/extractor/locomo_entity_extractor.py \
    --dataset benchmark/dataset/locomo/locomo10.json \
    --batch conv-26 conv-30 conv-41 \
    --use-chunking \
    --output benchmark/results/batch_extraction
```

**4. æ‰¹é‡å¤„ç†æ‰€æœ‰æ ·æœ¬**
```bash
python benchmark/extractor/locomo_entity_extractor.py \
    --dataset benchmark/dataset/locomo/locomo10.json \
    --batch-all \
    --use-chunking \
    --output benchmark/results/full_extraction
```

### æ•°æ®é›†åˆ¶ä½œå™¨ (dataset_maker.py)

ç”¨äºå°†æ‰€æœ‰æ ·æœ¬çš„å®ä½“å…³ç³»æŠ½å–ç»“æœæ•´åˆæˆç»Ÿä¸€çš„æ•°æ®é›†æ–‡ä»¶ã€‚

#### åŸºæœ¬åŠŸèƒ½

- **æ”¶é›†æŠ½å–ç»“æœ**ï¼šè‡ªåŠ¨æ‰«ææŠ½å–ç»“æœç›®å½•ï¼Œæ”¶é›†æ‰€æœ‰æ ·æœ¬æ•°æ®
- **å®ä½“å…³ç³»æ±‡æ€»**ï¼šç»Ÿè®¡å®ä½“å’Œå…³ç³»çš„é¢‘ç‡ã€ç±»å‹åˆ†å¸ƒç­‰
- **è·¨æ ·æœ¬åˆ†æ**ï¼šè¯†åˆ«å…±åŒå®ä½“å’Œå…³ç³»æ¨¡å¼
- **å¤šæ ¼å¼è¾“å‡º**ï¼šç”Ÿæˆå®Œæ•´ç‰ˆã€è½»é‡çº§ç‰ˆæœ¬å’Œç»Ÿè®¡æŠ¥å‘Š
- **æ ·æœ¬ç´¢å¼•**ï¼šåˆ›å»ºä¾¿äºæŸ¥è¯¢çš„æ ·æœ¬ç´¢å¼•æ–‡ä»¶

#### åŸºæœ¬å‘½ä»¤

```bash
python benchmark/extractor/dataset_maker.py [OPTIONS]
```

#### å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | å¿…éœ€ | è¯´æ˜ |
|------|------|------|------|
| `--results-dir` | str | âœ… | æŠ½å–ç»“æœç›®å½•è·¯å¾„ |
| `--output-dir` | str | âŒ | è¾“å‡ºç›®å½•è·¯å¾„ (é»˜è®¤: benchmark/dataset) |
| `--output-prefix` | str | âŒ | è¾“å‡ºæ–‡ä»¶å‰ç¼€ (é»˜è®¤: locomo_extracted) |

#### ä½¿ç”¨ç¤ºä¾‹

**1. åŸºæœ¬ç”¨æ³•**
```bash
python benchmark/extractor/dataset_maker.py \
    --results-dir benchmark/results/full_extraction
```

**2. æŒ‡å®šè¾“å‡ºç›®å½•å’Œå‰ç¼€**
```bash
python benchmark/extractor/dataset_maker.py \
    --results-dir benchmark/results/full_extraction \
    --output-dir benchmark/dataset/locomo/extraction \
    --output-prefix locomo_extracted
```

**3. å®Œæ•´å·¥ä½œæµç¤ºä¾‹**
```bash
# 1. å…ˆè¿›è¡Œå®ä½“å…³ç³»æŠ½å–
python benchmark/extractor/locomo_entity_extractor.py \
    --dataset benchmark/dataset/locomo/locomo10.json \
    --batch-all \
    --use-chunking \
    --output benchmark/results/fixed_full_extraction

# 2. ç„¶ååˆ¶ä½œæ•°æ®é›†
python benchmark/extractor/dataset_maker.py \
    --results-dir benchmark/results/fixed_full_extraction \
    --output-dir benchmark/dataset/locomo/extraction \
    --output-prefix locomo_extracted
```

#### è¾“å‡ºæ–‡ä»¶è¯´æ˜

æ•°æ®é›†åˆ¶ä½œå™¨ä¼šç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š

```
benchmark/dataset/locomo/extraction/
â”œâ”€â”€ locomo_extracted_full_dataset.json           # å®Œæ•´æ•°æ®é›†
â”œâ”€â”€ locomo_extracted_entity_relationship_summary.json  # å®ä½“å…³ç³»æ±‡æ€»
â”œâ”€â”€ locomo_extracted_sample_index.json           # æ ·æœ¬ç´¢å¼•
â”œâ”€â”€ locomo_extracted_lightweight.json            # è½»é‡çº§æ•°æ®é›†
â””â”€â”€ locomo_extracted_statistics_report.txt       # ç»Ÿè®¡æŠ¥å‘Š
```

**æ–‡ä»¶è¯¦ç»†è¯´æ˜ï¼š**

| æ–‡ä»¶ | æè¿° | ç”¨é€” |
|------|------|------|
| `*_full_dataset.json` | åŒ…å«æ‰€æœ‰æ ·æœ¬çš„å®Œæ•´æŠ½å–ç»“æœ | ä¸»è¦æ•°æ®é›†æ–‡ä»¶ |
| `*_entity_relationship_summary.json` | å®ä½“å…³ç³»çš„ç»Ÿè®¡æ±‡æ€»å’Œè·¨æ ·æœ¬åˆ†æ | æ•°æ®åˆ†æå’Œè´¨é‡è¯„ä¼° |
| `*_sample_index.json` | æ ·æœ¬å¿«é€Ÿç´¢å¼•ï¼ŒåŒ…å«åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯ | å¿«é€ŸæŸ¥è¯¢å’Œé€‰æ‹©æ ·æœ¬ |
| `*_lightweight.json` | ç§»é™¤äº†source_textç­‰å¤§å­—æ®µçš„è½»é‡ç‰ˆæœ¬ | å¿«é€ŸåŠ è½½å’Œé¢„è§ˆ |
| `*_statistics_report.txt` | äººç±»å¯è¯»çš„ç»Ÿè®¡æŠ¥å‘Š | æ•°æ®è´¨é‡æŠ¥å‘Š |

### å¯¹è¯è¯­ä¹‰å­˜å‚¨å™¨ (dataset_inserter.py)

ç”¨äºå°†LoCoMoæ•°æ®å­˜å‚¨åˆ°è¯­ä¹‰å›¾è°±ä¸­ï¼Œæ”¯æŒåŸå§‹æ•°æ®å’ŒæŠ½å–ç»“æœçš„æ··åˆå­˜å‚¨ã€‚

#### åŸºæœ¬ç”¨æ³•

```bash
# æµ‹è¯•æ‰€æœ‰å­˜å‚¨æ¨¡å¼
python benchmark/extractor/dataset_inserter.py

# æˆ–å•ç‹¬æµ‹è¯•æŸç§æ¨¡å¼
python -c "
from benchmark.extractor.dataset_inserter import ConversationSemanticStorage
storage = ConversationSemanticStorage()
stats = storage.store_conversation('conv-26')
print(stats)
"
```

#### ç¼–ç¨‹æ¥å£

```python
from benchmark.extractor.dataset_inserter import ConversationSemanticStorage

# 1. åˆ›å»ºå­˜å‚¨å™¨
storage = ConversationSemanticStorage()

# 2. å­˜å‚¨å•ä¸ªå¯¹è¯
stats = storage.store_conversation(
    sample_id="conv-26",
    include_raw=True,
    include_extracted=True
)

# 3. è·å–QAæµ‹è¯•æ•°æ®
qa_test_data = storage.get_qa_test_data(["conv-26"])

# 4. å­˜å‚¨æ‰€æœ‰å¯¹è¯
all_stats = storage.store_all_conversations()
```

### å‘½ä»¤è¡Œé€šç”¨å·¥å…· (extract_entities_cli.py)

é€šç”¨çš„å®ä½“å…³ç³»æŠ½å–å‘½ä»¤è¡Œå·¥å…·ã€‚

#### åŸºæœ¬å‘½ä»¤

```bash
python benchmark/extractor/extract_entities_cli.py [OPTIONS]
```

#### å‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | å¿…éœ€ | è¯´æ˜ |
|------|------|------|------|
| `--mode` | str | âœ… | æŠ½å–æ¨¡å¼ï¼šlocomo/text/conv26 |
| `--input` | str | âœ… | è¾“å…¥ï¼šæ•°æ®é›†è·¯å¾„æˆ–æ–‡æœ¬å†…å®¹ |
| `--output` | str | âŒ | è¾“å‡ºç›®å½•è·¯å¾„ |
| `--model` | str | âŒ | LLMæ¨¡å‹åç§° (é»˜è®¤deepseek-chat) |
| `--sample-limit` | int | âŒ | é™åˆ¶å¤„ç†çš„æ ·æœ¬æ•°é‡ |
| `--log-level` | str | âŒ | æ—¥å¿—çº§åˆ« (DEBUG/INFO/WARNING/ERROR) |

#### ä½¿ç”¨ç¤ºä¾‹

**1. å¤„ç†å•ä¸ªæ–‡æœ¬**
```bash
python benchmark/extractor/extract_entities_cli.py \
    --mode text \
    --input "Carolineä½åœ¨çº½çº¦ï¼Œæ˜¯å¿ƒç†å’¨è¯¢å¸ˆã€‚Melanieä½åœ¨åŠ å·ï¼Œæ˜¯è‰ºæœ¯å®¶ã€‚"
```

**2. ä¸“é—¨å¤„ç†conv-26**
```bash
python benchmark/extractor/extract_entities_cli.py \
    --mode conv26 \
    --input benchmark/dataset/locomo/locomo10.json \
    --output benchmark/results/conv26_extraction
```

## ğŸ“‚ è¾“å‡ºæ–‡ä»¶è¯¦ç»†è¯´æ˜

### å•æ ·æœ¬å¤„ç†è¾“å‡º

æ¯ä¸ªæ ·æœ¬å¤„ç†å®Œæˆåï¼Œä¼šåœ¨è¾“å‡ºç›®å½•ç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ç»“æ„ï¼š

```
{sample_id}_entity_extraction_{timestamp}/
â”œâ”€â”€ extraction.log                                   # å¤„ç†æ—¥å¿—
â”œâ”€â”€ {sample_id}_full_conversation.txt               # å®Œæ•´å¯¹è¯æ–‡æœ¬
â”œâ”€â”€ {sample_id}_semantic_graph/                     # è¯­ä¹‰å›¾è°±ç›®å½•
â”‚   â”œâ”€â”€ semantic_map_data/                         # SemanticMapæ•°æ®
â”‚   â”‚   â”œâ”€â”€ memory_units.pkl                       # å†…å­˜å•å…ƒæ•°æ®
â”‚   â”‚   â”œâ”€â”€ memory_spaces.pkl                      # å†…å­˜ç©ºé—´æ•°æ®
â”‚   â”‚   â””â”€â”€ faiss_index.faiss                      # FAISSç´¢å¼•
â”‚   â”œâ”€â”€ semantic_graph.pkl                         # NetworkXå›¾ç»“æ„
â”‚   â””â”€â”€ management_state.pkl                       # å†…å­˜ç®¡ç†çŠ¶æ€
â”œâ”€â”€ {sample_id}_extraction_results.json            # æŠ½å–ç»“æœJSON
â”œâ”€â”€ {sample_id}_detailed_analysis.json             # è¯¦ç»†åˆ†æç»“æœ
â””â”€â”€ {sample_id}_summary_report.txt                 # æ‘˜è¦æŠ¥å‘Š
```

### å…³é”®æ–‡ä»¶è¯´æ˜

| æ–‡ä»¶ | æ ¼å¼ | è¯´æ˜ |
|------|------|------|
| `semantic_graph.pkl` | Pickle | NetworkXå›¾ç»“æ„ï¼ŒåŒ…å«æ‰€æœ‰èŠ‚ç‚¹å’Œè¾¹ |
| `semantic_map_data/` | ç›®å½• | SemanticMapçš„å®Œæ•´çŠ¶æ€æ•°æ® |
| `*_extraction_results.json` | JSON | æŠ½å–çš„å®ä½“ã€å…³ç³»å’Œç»Ÿè®¡ä¿¡æ¯ |
| `*_detailed_analysis.json` | JSON | è¯¦ç»†çš„ç½‘ç»œåˆ†æå’Œå®ä½“å…³ç³»åˆ†æ |
| `*_summary_report.txt` | Text | äººç±»å¯è¯»çš„å¤„ç†æ‘˜è¦æŠ¥å‘Š |
| `extraction.log` | Text | è¯¦ç»†çš„å¤„ç†æ—¥å¿—å’Œé”™è¯¯ä¿¡æ¯ |

## ğŸ’¡ ç¼–ç¨‹æ¥å£ä½¿ç”¨

### åŸºæœ¬å®ä½“å…³ç³»æŠ½å–

```python
from benchmark.llm_utils.llm_client import LLMClient
from benchmark.extractor.entity_relation_extractor import EntityRelationExtractor

# åˆå§‹åŒ–
llm_client = LLMClient(model_name="deepseek-chat")
extractor = EntityRelationExtractor(llm_client)

# æŠ½å–å®ä½“å’Œå…³ç³»
text = "Aliceä½åœ¨çº½çº¦ï¼Œæ˜¯ä¸€ååŒ»ç”Ÿã€‚Bobä½åœ¨åŠ å·ï¼Œæ˜¯å¥¹çš„æœ‹å‹ã€‚"
entities, relationships, keywords = extractor.extract_entities_and_relations(text)

print(f"å®ä½“: {len(entities)} ä¸ª")
print(f"å…³ç³»: {len(relationships)} ä¸ª")
print(f"å…³é”®è¯: {keywords}")
```

### LoCoMoä¸“ç”¨å¤„ç†å™¨

```python
from benchmark.extractor.locomo_entity_extractor import LoCoMoEntityExtractor

# åˆå§‹åŒ–å¤„ç†å™¨
extractor = LoCoMoEntityExtractor("benchmark/dataset/locomo/locomo10.json")

# åˆ—å‡ºå¯ç”¨æ ·æœ¬
samples = extractor.list_available_samples()
print(f"å¯ç”¨æ ·æœ¬: {samples}")

# è·å–æ ·æœ¬ä¿¡æ¯
info = extractor.get_sample_info("conv-26")
print(f"æ ·æœ¬ä¿¡æ¯: {info}")

# å¤„ç†å•ä¸ªæ ·æœ¬
result = extractor.extract_entities_and_relations_for_sample(
    sample_id="conv-26",
    use_chunking=True,
    save_intermediate=True
)

print(f"å¤„ç†ç»“æœ: {result['extraction_results']}")
```

### è¯­ä¹‰å›¾é›†æˆ

```python
from dev.semantic_graph import SemanticGraph
from benchmark.extractor.semantic_graph_integrator import SemanticGraphIntegrator

# åˆ›å»ºè¯­ä¹‰å›¾
graph = SemanticGraph()
integrator = SemanticGraphIntegrator(graph)

# å¤„ç†å†…å­˜å•å…ƒè¿›è¡Œå®ä½“æŠ½å–
result = integrator.process_memory_unit_for_entities(unit)

# æ‰¹é‡å¤„ç†
batch_results = integrator.batch_extract_entities_from_space(
    space_name="locomo_dialogs",
    max_units=50
)
```

## âš™ï¸ é…ç½®è¯´æ˜

### LLMé…ç½®

æ”¯æŒå¤šç§LLMæ¨¡å‹ï¼š

```python
# DeepSeek (æ¨è)
llm_client = LLMClient(model_name="deepseek-chat")
llm_client = LLMClient(model_name="deepseek-reasoner")

# OpenAI GPT
llm_client = LLMClient(model_name="gpt-4o-mini")
llm_client = LLMClient(model_name="gpt-4o")
```

### å®ä½“ç±»å‹é…ç½®

æ”¯æŒçš„å®ä½“ç±»å‹ï¼š
- `person`: äººç‰©
- `organization`: ç»„ç»‡æœºæ„
- `geo`: åœ°ç†ä½ç½®
- `event`: äº‹ä»¶
- `category`: ç±»åˆ«/æ¦‚å¿µ

### å…³ç³»ç±»å‹é…ç½®

æ”¯æŒçš„å…³ç³»ç±»å‹ï¼š
- `FAMILY`: å®¶åº­å…³ç³»
- `WORK`: å·¥ä½œå…³ç³»
- `FRIEND`: æœ‹å‹å…³ç³»
- `LOCATION`: ä½ç½®å…³ç³»
- `TEMPORAL`: æ—¶é—´å…³ç³»
- `TOPIC`: ä¸»é¢˜å…³ç³»
- `RELATED_TO`: ä¸€èˆ¬å…³è”å…³ç³»

### åˆ†å—å¤„ç†é…ç½®

```python
# æ™ºèƒ½åˆ†å—é…ç½®
max_tokens = 60000  # æœ€å¤§tokenæ•°
strategy = "intelligent"  # åˆ†å—ç­–ç•¥

# è‡ªå®šä¹‰åˆ†å—
extractor.smart_text_chunking(text, max_tokens=50000)
```

## ğŸ”§ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### å¤„ç†å¤§é‡æ•°æ®æ—¶

1. **ä½¿ç”¨åˆ†å—å¤„ç†**ï¼šå¯ç”¨`--use-chunking`å‚æ•°å¤„ç†é•¿æ–‡æœ¬
2. **åˆ†æ‰¹å¤„ç†**ï¼šä½¿ç”¨`--batch`æŒ‡å®šéƒ¨åˆ†æ ·æœ¬ï¼Œé¿å…ä¸€æ¬¡å¤„ç†è¿‡å¤š
3. **ä¿å­˜ä¸­é—´ç»“æœ**ï¼šä½¿ç”¨`--save-intermediate`é˜²æ­¢æ„å¤–ä¸­æ–­
4. **è°ƒæ•´æ—¥å¿—çº§åˆ«**ï¼šä½¿ç”¨`--log-level WARNING`å‡å°‘æ—¥å¿—è¾“å‡º

### å†…å­˜ä¼˜åŒ–

```bash
# é™åˆ¶å¤„ç†æ ·æœ¬æ•°
python benchmark/extractor/locomo_entity_extractor.py \
    --batch conv-26 conv-30 \
    --use-chunking \
    --output results/small_batch

# ä¸ä¿å­˜ä¸­é—´ç»“æœï¼ˆèŠ‚çœç£ç›˜ç©ºé—´ï¼‰
python benchmark/extractor/locomo_entity_extractor.py \
    --sample-id conv-26 \
    --use-chunking
```

### APIè°ƒç”¨ä¼˜åŒ–

- åˆç†è®¾ç½®å¤„ç†é—´éš”ï¼Œé¿å…APIé™æµ
- ä½¿ç”¨è¾ƒå°çš„æ ·æœ¬é›†è¿›è¡Œæµ‹è¯•ï¼Œç¡®è®¤æ•ˆæœåå†æ‰©å¤§è§„æ¨¡
- ç›‘æ§APIä½¿ç”¨é‡å’Œæˆæœ¬

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

**1. æ¨¡å—å¯¼å…¥é”™è¯¯**
```bash
ModuleNotFoundError: No module named 'benchmark'
```
è§£å†³æ–¹æ¡ˆï¼šç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œå‘½ä»¤
```bash
cd /home/zyh/code/AgentMemorySystem
```

**2. æ•°æ®é›†è·¯å¾„é”™è¯¯**
```bash
ValueError: æ•°æ®é›†åŠ è½½å¤±è´¥
```
è§£å†³æ–¹æ¡ˆï¼šæ£€æŸ¥æ•°æ®é›†æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®
```bash
ls benchmark/dataset/locomo/locomo10.json
```

**3. LLM APIé”™è¯¯**
æ£€æŸ¥APIå¯†é’¥å’Œç½‘ç»œè¿æ¥ï¼š
```bash
echo $DEEPSEEK_API_KEY
echo $OPENAI_API_KEY
```

**4. å†…å­˜ä¸è¶³**
å‡å°‘æ‰¹é‡å¤„ç†çš„æ ·æœ¬æ•°é‡ï¼Œæˆ–ä½¿ç”¨åˆ†å—å¤„ç†ã€‚

**5. æŠ½å–ç»“æœä¸ºç©º**
- æ£€æŸ¥è¾“å…¥æ–‡æœ¬æ˜¯å¦æœ‰æ•ˆ
- ç¡®è®¤LLMæ¨¡å‹æ˜¯å¦å¯ç”¨
- æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶äº†è§£è¯¦ç»†é”™è¯¯ä¿¡æ¯

### è°ƒè¯•æ¨¡å¼

å¼€å¯è¯¦ç»†æ—¥å¿—è¿›è¡Œè°ƒè¯•ï¼š
```bash
python benchmark/extractor/locomo_entity_extractor.py \
    --dataset benchmark/dataset/locomo/locomo10.json \
    --sample-id conv-26 \
    --save-intermediate
```

æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶ï¼š
```bash
tail -f benchmark/results/*/extraction.log
```

### æ•°æ®éªŒè¯

éªŒè¯æŠ½å–ç»“æœçš„è´¨é‡ï¼š
```bash
# 1. æ£€æŸ¥æŠ½å–ç»“æœæ–‡ä»¶
cat benchmark/results/conv-26_*/conv-26_extraction_results.json | jq '.extraction_statistics'

# 2. æŸ¥çœ‹ç»Ÿè®¡æŠ¥å‘Š
cat benchmark/results/conv-26_*/conv-26_summary_report.txt

# 3. éªŒè¯æ•°æ®é›†åˆ¶ä½œç»“æœ
cat benchmark/dataset/locomo/extraction/locomo_extracted_statistics_report.txt
```

## ğŸ“ˆ å®Œæ•´å·¥ä½œæµç¨‹ç¤ºä¾‹

### ä»é›¶å¼€å§‹çš„å®Œæ•´å¤„ç†æµç¨‹

```bash
# 1. è®¾ç½®ç¯å¢ƒ
cd /home/zyh/code/AgentMemorySystem
export DEEPSEEK_API_KEY="your-api-key"

# 2. æŸ¥çœ‹å¯ç”¨æ ·æœ¬
python benchmark/extractor/locomo_entity_extractor.py \
    --dataset benchmark/dataset/locomo/locomo10.json \
    --list-samples

# 3. æµ‹è¯•å•ä¸ªæ ·æœ¬
python benchmark/extractor/locomo_entity_extractor.py \
    --dataset benchmark/dataset/locomo/locomo10.json \
    --sample-id conv-26 \
    --use-chunking \
    --save-intermediate \
    --output benchmark/results/test_extraction

# 4. æ‰¹é‡å¤„ç†æ‰€æœ‰æ ·æœ¬
python benchmark/extractor/locomo_entity_extractor.py \
    --dataset benchmark/dataset/locomo/locomo10.json \
    --batch-all \
    --use-chunking \
    --output benchmark/results/full_extraction

# 5. åˆ¶ä½œæ•°æ®é›†
python benchmark/extractor/dataset_maker.py \
    --results-dir benchmark/results/full_extraction \
    --output-dir benchmark/dataset/locomo/extraction \
    --output-prefix locomo_extracted

# 6. éªŒè¯ç»“æœ
cat benchmark/dataset/locomo/extraction/locomo_extracted_statistics_report.txt
```

### é’ˆå¯¹ç‰¹å®šéœ€æ±‚çš„å®šåˆ¶æµç¨‹

```bash
# ä»…å¤„ç†ç‰¹å®šæ ·æœ¬é›†
python benchmark/extractor/locomo_entity_extractor.py \
    --dataset benchmark/dataset/locomo/locomo10.json \
    --batch conv-26 conv-30 conv-41 \
    --use-chunking \
    --output benchmark/results/selected_samples

# åˆ¶ä½œå®šåˆ¶æ•°æ®é›†
python benchmark/extractor/dataset_maker.py \
    --results-dir benchmark/results/selected_samples \
    --output-dir benchmark/dataset/custom \
    --output-prefix custom_extracted
```

## ğŸ”— ç›¸å…³å·¥å…·

- **ä»»åŠ¡è¯„ä¼°**: [`benchmark/task_eval/`](../task_eval/) - ä½¿ç”¨æŠ½å–çš„æ•°æ®è¿›è¡ŒQAè¯„ä¼°
- **è¯­ä¹‰å›¾è°±**: [`dev/semantic_graph.py`](../../dev/semantic_graph.py) - æ ¸å¿ƒè¯­ä¹‰å›¾è°±å®ç°
- **LLMå·¥å…·**: [`benchmark/llm_utils/`](../llm_utils/) - LLMå®¢æˆ·ç«¯å’Œå·¥å…·

## ğŸ“„ ç‰ˆæœ¬å†å²

- **v1.0**: åŸºç¡€å®ä½“å…³ç³»æŠ½å–åŠŸèƒ½
- **v1.1**: æ·»åŠ JSONæ ¼å¼è¾“å‡ºæ”¯æŒ
- **v1.2**: LoCoMoä¸“ç”¨å¤„ç†å™¨
- **v1.3**: æ‰¹é‡å¤„ç†å’ŒçŸ¥è¯†å›¾è°±æ„å»º
- **v1.4**: æ™ºèƒ½åˆ†å—å’Œä½ç½®è¿½è¸ª
- **v1.5**: æ•°æ®é›†åˆ¶ä½œå™¨å’Œå®Œæ•´å·¥ä½œæµç¨‹
- **v1.6**: å¯¹è¯è¯­ä¹‰å­˜å‚¨å’ŒæŸ¥è¯¢åŠŸèƒ½

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›æœ¬å·¥å…·ã€‚

### å¼€å‘ç¯å¢ƒè®¾ç½®

```bash
git clone <repository-url>
cd AgentMemorySystem
pip install -r requirements.txt
```

### æµ‹è¯•

è¿è¡Œå¿«é€Ÿæµ‹è¯•ç¡®ä¿åŠŸèƒ½æ­£å¸¸ï¼š
```bash
python benchmark/extractor/example.py
```

## ğŸ“ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š
- æäº¤Issue: [GitHub Issues]
- é‚®ç®±: zhangyuhan25@otcaix.iscas.ac.cn

---

*æœ€åæ›´æ–°: 2025å¹´7æœˆ8æ—¥*